from flask import Flask, request, jsonify
import opennsfw2 as n2
from PIL import Image
import io
import os
import tempfile
import cv2
import numpy as np

app = Flask(__name__)

# Ø¹ØªØ¨Ø© Ø§Ù„ÙƒØ´Ù (0.0 - 1.0) - ÙƒÙ„Ù…Ø§ Ø§Ø±ØªÙØ¹ Ø§Ù„Ø±Ù‚Ù…ØŒ Ø£Ù‚Ù„ Ø­Ø³Ø§Ø³ÙŠØ©
NSFW_THRESHOLD = 0.6

@app.route('/')
def home():
    return """
    <h1>NSFW Detection API (Ù…Ø­Ù„ÙŠ - 2025)</h1>
    <p>Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù€ endpoints:</p>
    <ul>
        <li>POST /detect/image - Ù„Ù„ØµÙˆØ±</li>
        <li>POST /detect/video - Ù„Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª</li>
    </ul>
    <p>Ø£Ø±Ø³Ù„ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø­Ù‚Ù„ 'file'</p>
    """

@app.route('/detect/image', methods=['POST'])
def detect_image():
    if 'file' not in request.files:
        return jsonify({"error": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹"}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº"}), 400
    
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
        img_bytes = file.read()
        pil_image = Image.open(io.BytesIO(img_bytes))
        
        # Ø§Ù„ÙƒØ´Ù
        probability = n2.predict_image(pil_image)
        is_nsfw = probability > NSFW_THRESHOLD
        
        return jsonify({
            "filename": file.filename,
            "nsfw_probability": round(probability, 4),
            "is_nsfw": is_nsfw,
            "threshold": NSFW_THRESHOLD,
            "message": "NSFW" if is_nsfw else "Ø¢Ù…Ù† (SFW)"
        })
    
    except Exception as e:
        return jsonify({"error": f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}"}), 500

@app.route('/detect/video', methods=['POST'])
def detect_video():
    if 'file' not in request.files:
        return jsonify({"error": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹"}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº"}), 400
    
    try:
        # Ø­ÙØ¸ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¤Ù‚ØªÙ‹Ø§
        temp_fd, temp_path = tempfile.mkstemp(suffix=os.path.splitext(file.filename)[1])
        file.save(temp_path)
        
        # Ø§Ù„ÙƒØ´Ù ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (ÙØ­Øµ Ø¥Ø·Ø§Ø±Ø§Øª Ù…Ù†ØªØ¸Ù…Ø©)
        elapsed, probabilities = n2.predict_video_frames(temp_path, frame_interval=16)  # ÙƒÙ„ ~0.5 Ø«Ø§Ù†ÙŠØ©
        avg_probability = float(np.mean(probabilities)) if probabilities else 0.0
        is_nsfw = avg_probability > NSFW_THRESHOLD
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        os.close(temp_fd)
        os.remove(temp_path)
        
        return jsonify({
            "filename": file.filename,
            "average_nsfw_probability": round(avg_probability, 4),
            "frames_analyzed": len(probabilities),
            "is_nsfw": is_nsfw,
            "threshold": NSFW_THRESHOLD,
            "message": "NSFW" if is_nsfw else "Ø¢Ù…Ù† (SFW)"
        })
    
    except Exception as e:
        return jsonify({"error": f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {str(e)}"}), 500

if __name__ == '__main__':
    print("ğŸš€ NSFW Detection API ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† Ø¹Ù„Ù‰ http://127.0.0.1:5000")
    print("Ø§Ø³ØªØ®Ø¯Ù… /detect/image Ø£Ùˆ /detect/video")
    app.run(host='0.0.0.0', port=5000, debug=True)